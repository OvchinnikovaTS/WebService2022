{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gD_VHjdSwRkj5SD3-te2O-XFZ_WFBbU8",
      "authorship_tag": "ABX9TyPXtQlw3veS3XGuOANQmTb6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OvchinnikovaTS/WebService2022/blob/main/DL_team33.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Easy OCR\n",
        "\n"
      ],
      "metadata": {
        "id": "2FSTbfQ2evk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr\n",
        "!pip install imutils\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXmkVjM_e6Nl",
        "outputId": "60483b21-d4f1-457d-c02a-b7853673b2f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting easyocr\n",
            "  Downloading easyocr-1.6.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.7.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from easyocr) (7.1.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.8.4)\n",
            "Collecting python-bidi\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.18.3)\n",
            "Collecting opencv-python-headless<=4.5.4.60\n",
            "  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from easyocr) (6.0)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 31.2 MB/s \n",
            "\u001b[?25hCollecting pyclipper\n",
            "  Downloading pyclipper-1.3.0.post3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (604 kB)\n",
            "\u001b[K     |████████████████████████████████| 604 kB 47.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->easyocr) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->easyocr) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-bidi->easyocr) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->easyocr) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->easyocr) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->easyocr) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->easyocr) (2.10)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (1.4.4)\n",
            "Installing collected packages: python-bidi, pyclipper, opencv-python-headless, ninja, easyocr\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "Successfully installed easyocr-1.6.2 ninja-1.10.2.3 opencv-python-headless-4.5.4.60 pyclipper-1.3.0.post3 python-bidi-0.4.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import imutils\n",
        "import easyocr"
      ],
      "metadata": {
        "id": "E_g58dl5e-P9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('2.jpg')\n",
        "#image4.jpg')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "h4yUZys0e_Y9",
        "outputId": "564e5be2-a10b-4119-f44c-4354466e4feb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f40574507d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#image4.jpg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bfilter = cv2.bilateralFilter(gray, 11, 17, 17) #Noise reduction\n",
        "edged = cv2.Canny(bfilter, 30, 200) #Edge detection\n",
        "plt.imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "6gItWG_3fCrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "contours = imutils.grab_contours(keypoints)\n",
        "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]"
      ],
      "metadata": {
        "id": "ij6uKlOZfGP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location = None\n",
        "for contour in contours:\n",
        "    approx = cv2.approxPolyDP(contour, 10, True)\n",
        "    if len(approx) == 4:\n",
        "        location = approx\n",
        "        break\n",
        "location\n",
        "array([[[300, 540]],\n",
        "\n",
        "       [[306, 589]],\n",
        "\n",
        "       [[543, 592]],\n",
        "\n",
        "       [[538, 543]]], dtype=int32)\n",
        "mask = np.zeros(gray.shape, np.uint8)\n",
        "new_image = cv2.drawContours(mask, [location], 0,255, -1)\n",
        "new_image = cv2.bitwise_and(img, img, mask=mask)\n",
        "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "kqzxgNrufJnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "<matplotlib.image.AxesImage at 0x19bd8e22a20>\n",
        "\n",
        "(x,y) = np.where(mask==255)\n",
        "(x1, y1) = (np.min(x), np.min(y))\n",
        "(x2, y2) = (np.max(x), np.max(y))\n",
        "cropped_image = gray[x1:x2+1, y1:y2+1]\n",
        "plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))\n",
        "<matplotlib.image.AxesImage at 0x19b9a545400>\n",
        "\n",
        "4. Use Easy OCR To Read Text\n",
        "reader = easyocr.Reader(['en'])\n",
        "result = reader.readtext(cropped_image)\n",
        "result\n",
        "[([[0, 0], [244, 0], [244, 53], [0, 53]], 'H982FKL', 0.6736311316490173)]\n",
        "5. Render Result\n",
        "text = result[0][-2]\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "res = cv2.putText(img, text=text, org=(approx[0][0][0], approx[1][0][1]+60), fontFace=font, fontScale=1, color=(0,255,0), thickness=2, lineType=cv2.LINE_AA)\n",
        "res = cv2.rectangle(img, tuple(approx[0][0]), tuple(approx[2][0]), (0,255,0),3)\n",
        "plt.imshow(cv2.cvtColor(res, cv2.COLOR_BGR2RGB))\n",
        "<matplotlib.image.AxesImage at 0x19ba563dbe0>"
      ],
      "metadata": {
        "id": "uF70RaoJfOqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perspective Transform"
      ],
      "metadata": {
        "id": "zXRJ8fZta2nI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgABbH-e1UkK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "!pip install -U -q PyDrive\n",
        "import numpy as np \n",
        "import json \n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "!ls /content/gdrive/\"MyDrive\"/\"data_cars_CV\"\n",
        "#\"data_cars_CV\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP_1538dgOuy",
        "outputId": "f99b560d-0341-4956-8a60-232f6eb9af9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "submission.csv\ttest  train  train.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "#DATA_DIR = '../input/car-plates-ocr/data/'\n",
        "DATA_DIR = '../data_cars_CV/'\n",
        "#print(DATA_DIR)\n",
        "NUM_SAMPLES = 5\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAbZORTYf8pR",
        "outputId": "432b3ed8-76ba-45a0-9b23-3c335f805765"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "../data_cars_CV/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_marks = json.load(open(os.path.join(DATA_DIR, 'train.json')))\n",
        "sample_marks = np.random.choice(train_marks, size=NUM_SAMPLES)\n",
        "def order_points(pts):\n",
        "    \n",
        "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
        "    \n",
        "    s = pts.sum(axis = 1)\n",
        "    rect[0] = pts[np.argmin(s)]\n",
        "    rect[2] = pts[np.argmax(s)]\n",
        "    \n",
        "    diff = np.diff(pts, axis = 1)\n",
        "    rect[1] = pts[np.argmin(diff)]\n",
        "    rect[3] = pts[np.argmax(diff)]\n",
        "    \n",
        "    return rect\n",
        "\n",
        "\n",
        "def four_point_transform(image, pts):\n",
        "    \n",
        "    rect = order_points(pts)\n",
        "    \n",
        "    tl, tr, br, bl = pts\n",
        "    \n",
        "    width_1 = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "    width_2 = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "    max_width = max(int(width_1), int(width_2))\n",
        "    \n",
        "    height_1 = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "    height_2 = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "    max_height = max(int(height_1), int(height_2))\n",
        "    \n",
        "    dst = np.array([\n",
        "        [0, 0],\n",
        "        [max_width, 0],\n",
        "        [max_width, max_height],\n",
        "        [0, max_height]], dtype = \"float32\")\n",
        "    \n",
        "    M = cv2.getPerspectiveTransform(rect, dst)\n",
        "    warped = cv2.warpPerspective(image, M, (max_width, max_height))\n",
        "    return warped\n",
        "plt.figure(figsize=(25, 16))\n",
        "for i, mark in enumerate(sample_marks):\n",
        "    box = np.array(mark['nums'][0]['box'])\n",
        "    image = cv2.imread(os.path.join(DATA_DIR, mark['file']))\n",
        "    image = image[..., ::-1]\n",
        "    \n",
        "    \n",
        "    plt.subplot(2, NUM_SAMPLES, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(2, NUM_SAMPLES, i + NUM_SAMPLES + 1)\n",
        "    plt.imshow(four_point_transform(image, box))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VF7XQcaZsC3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Робофлоу (YOLOv7)"
      ],
      "metadata": {
        "id": "DpnRkBtjWr7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download YOLOv7 repository and install requirements\n",
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "VvnV8X9MVrio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"DEMO_KEYS\")\n",
        "project = rf.workspace(\"YOUR-WORKSPACE\").project(\"YOUR-PROJECT\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ],
      "metadata": {
        "id": "B6K0yp_uXPC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REPLACE with your custom code snippet generated above\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YOUR API KEY\")\n",
        "project = rf.workspace(\"YOUR-WORKSPACE\").project(\"YOUR-PROJECT\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ],
      "metadata": {
        "id": "zIGn4gA7VuZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Керас, датасет Цифар 10"
      ],
      "metadata": {
        "id": "r4pVytF_WmNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Задаем seed для повторяемости результатов\n",
        "numpy.random.seed(42)\n",
        "\n",
        "# Загружаем данные\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# Размер мини-выборки\n",
        "batch_size = 32\n",
        "# Количество классов изображений\n",
        "nb_classes = 10\n",
        "# Количество эпох для обучения\n",
        "nb_epoch = 25\n",
        "# Размер изображений\n",
        "img_rows, img_cols = 32, 32\n",
        "# Количество каналов в изображении: RGB\n",
        "img_channels = 3\n",
        "\n",
        "# Нормализуем данные\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Преобразуем метки в категории\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "# Создаем последовательную модель\n",
        "model = Sequential()\n",
        "# Первый сверточный слой\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                        input_shape=(32, 32, 3), activation='relu'))\n",
        "# Второй сверточный слой\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "# Первый слой подвыборки\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Слой регуляризации Dropout\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Третий сверточный слой\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "# Четвертый сверточный слой\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# Второй слой подвыборки\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Слой регуляризации Dropout\n",
        "model.add(Dropout(0.25))\n",
        "# Слой преобразования данных из 2D представления в плоское\n",
        "model.add(Flatten())\n",
        "# Полносвязный слой для классификации\n",
        "model.add(Dense(512, activation='relu'))\n",
        "# Слой регуляризации Dropout\n",
        "model.add(Dropout(0.5))\n",
        "# Выходной полносвязный слой\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "# Задаем параметры оптимизации\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "# Обучаем модель\n",
        "model.fit(X_train, Y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=nb_epoch,\n",
        "              validation_split=0.1,\n",
        "              shuffle=True,\n",
        "              verbose=2)\n",
        "\n",
        "# Оцениваем качество обучения модели на тестовых данных\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "Sc5xnyMCNAgk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "99cd7b18-56da-4d1a-a9b7-863d6bd3219c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6eff5f083bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Задаем seed для повторяемости результатов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'SGD' from 'keras.optimizers' (/usr/local/lib/python3.7/dist-packages/keras/optimizers.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}